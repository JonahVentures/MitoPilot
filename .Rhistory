{paste(colnames(mapping), collapse=',')},
PRIMARY KEY (ID)
)"
)
# Create sqlite connection
con <- DBI::dbConnect(RSQLite::SQLite(), dbname = db_path)
db_path=here::here()
# Create sqlite connection
con <- DBI::dbConnect(RSQLite::SQLite(), dbname = db_path)
db_path
db_path
db_path=file.path(here::here(),".sqlite")
# Create sqlite connection
con <- DBI::dbConnect(RSQLite::SQLite(), dbname = db_path)
glue::glue_sql(
"CREATE TABLE samples (
{paste(colnames(mapping), collapse=',')},
PRIMARY KEY (ID)
)"
)
glue::glue_sql(
"CREATE TABLE samples (
{colnames(mapping)}*,
PRIMARY KEY (ID)
)",
.con = con
)
glue::glue_sql(
"CREATE TABLE samples (
{cols*},
PRIMARY KEY (ID)
)",
cols = colnames(mapping),
.con = con
)
DBI::dbListTables(conn = )
DBI::dbListTables(con)
DBI::dbDisconnect(con)
con <- DBI::dbConnect(RSQLite::SQLite(), ":memory:")
iris2 <- iris
colnames(iris2) <- gsub("[.]", "_", tolower(colnames(iris)))
DBI::dbWriteTable(con, "iris", iris2)
var <- "sepal_width"
tbl <- "iris"
num <- 2
val <- "setosa"
glue_sql("
SELECT {`var`}
FROM {`tbl`}
WHERE {`tbl`}.sepal_length > {num}
AND {`tbl`}.species = {val}
", .con = con)
library(glue)
glue_sql("
SELECT {`var`}
FROM {`tbl`}
WHERE {`tbl`}.sepal_length > {num}
AND {`tbl`}.species = {val}
", .con = con)
DBI::dbDisconnect(con)
# Create sqlite connection
con <- DBI::dbConnect(RSQLite::SQLite(), dbname = db_path)
glue::glue_sql(
"CREATE TABLE samples (
{cols*},
PRIMARY KEY (ID)
)",
cols = colnames(mapping),
.con = con
) |> DBI::dbExecute()
? DBI::dbExecute()
glue::glue_sql(
"CREATE TABLE samples (
{cols*},
PRIMARY KEY (ID)
)",
cols = colnames(mapping),
.con = con
) |> DBI::dbExecute(con, statement = _)
DBI::dbListTables(con)
glue::glue_sql(
"CREATE TABLE samples (
{cols*},
PRIMARY KEY (ID)
)",
cols = colnames(mapping),
.con = con
)
?DBI::SQL()
?dplyr::rows_upsert
mapping |>
dplyr::rows_upsert(
"mapping",
con,
in_place = TRUE,
by = "ID"
)
dplyr::tbl(con, "samples") |>
dplyr::rows_upsert(
mapping,
in_place = TRUE,
by = "ID"
)
dplyr::tbl(con, "samples") |>
dplyr::rows_upsert(
mapping,
in_place = TRUE,
copy = TRUE,
by = "ID"
)
# Add pre-processing options table
DBI::dbExecute(
con,
"CREATE TABLE preprocess_opts (
opts TEXT NOT NULL,
cpus INTEGER,
memory INTEGER,
fastp TEXT,
PRIMARY KEY (opts)
);"
)
# Add pre-processing options table
DBI::dbExecute(
con,
"CREATE TABLE preprocess_opts (
opts TEXT NOT NULL,
cpus INTEGER,
memory INTEGER,
fastp TEXT,
PRIMARY KEY (opts)
);"
)
dplyr::tbl(con, "preprocess_opts") |>
dplyr::rows_upsert(
data.frame(
opts = "default",
opt_cpus = 8,
opt_memory = '8.GB',
opt_fastp = "--trim_poly_g --correction"
),
in_place = TRUE,
copy = TRUE,
by = "ID"
)
dplyr::tbl(con, "preprocess_opts") |>
dplyr::rows_upsert(
data.frame(
opts = "default",
cpus = 8,
memory = '8.GB',
fastp = "--trim_poly_g --correction"
),
in_place = TRUE,
copy = TRUE,
by = "ID"
)
dplyr::tbl(con, "preprocess_opts") |>
dplyr::rows_upsert(
data.frame(
opts = "default",
cpus = 8,
memory = '8.GB',
fastp = "--trim_poly_g --correction"
),
in_place = TRUE,
copy = TRUE,
by = "opts"
)
usethis::use_r("init_config")
output = file.path(here::here(), "nextflow.config")
output
writeLines("plugins {", output)
writeLines("plugins {\n\tid 'nf-sqldb", output)
writeLines("plugins {\n\tid 'nf-sqldb'", output)
writeLines("\tid 'nf-amazon'", output, append = TRUE)
cat("\tid 'nf-amazon'", output, append = TRUE)
cat("\tid 'nf-amazon'", file=output, append = TRUE)
# Write plugins block ----
cat("plugins {\n\tid 'nf-sqldb@0.5.0'", file=output)
cat("\tid 'nf-amazon'", file=output, append = TRUE)
cat("}\n\n")
# Containers ----
if(docker){
cat("process.container = 'docker'\n", file=output, append = TRUE)
}
cat("process.container = 'docker'\n", file=output, append = TRUE)
# database connection ----
cat("sql.db.sqlite.url = 'jdbc:sqlite:.sqlite'\n", file=output, append = TRUE)
# Write plugins block ----
cat("plugins {\n\tid 'nf-sqldb@0.5.0'", file=output)
cat("\tid 'nf-amazon'", file=output, append = TRUE)
cat("}\n\n", file=output, append = TRUE)
?cat
# Write plugins block ----
cat("plugins {\n\tid 'nf-sqldb@0.5.0'", file=output)
cat("\tid 'nf-amazon'", file=output, append = TRUE, sep = "\n")
cat("}", file=output, append = TRUE, sep = "\n")
# Write plugins block ----
cat("plugins {\n\tid 'nf-sqldb@0.5.0'", file=output, sep = "\n")
cat("\tid 'nf-amazon'", file=output, append = TRUE, sep = "\n")
cat("}", file=output, append = TRUE, sep = "\n")
cat("process.container = 'docker'", file=output, append = TRUE, sep = "\n")
# database connection ----
cat("sql.db.sqlite.url = 'jdbc:sqlite:.sqlite'", file=output, append = TRUE, sep = "\n")
# database connection ----
cat("sql.db.sqlite.url = 'jdbc:sqlite:.sqlite'", file=output, append = TRUE, sep = "\n")
executor = "local"
container = '220571360826.dkr.ecr.us-east-1.amazonaws.com/mitopilot'
containerOptions = NULL
# Process block ----
process <- list(
executor = executor,
container = container,
containerOptions = containerOptions
) |>
purrr::compact()
process
usethis::use_r("utils")
aws = list(
queue = "jv-assemble",
region = "us-east-1",
batch = list(
cliPath = '/home/ec2-user/miniconda/bin/aws',
maxParallelTransfers = 8
),
client = maxConnections = 16
aws = list(
queue = "jv-assemble",
region = "us-east-1",
batch = list(
cliPath = '/home/ec2-user/miniconda/bin/aws',
maxParallelTransfers = 8
),
client = list(
maxConnections = 16
)
)
jsonlite::toJSON(aws, auto_unbox = TRUE)
# Process block ----
process <- list(
executor = executor,
container = container,
containerOptions = containerOptions
) |>
purrr::compact()
process$queue = aws$queue %||% "<<must specify a aws batch queue>>"
aws$queue <- NULL
devtools::load_all(".")
process$queue = aws$queue %||% "<<must specify a aws batch queue>>"
aws$queue <- NULL
jsonlite::toJSON(aws, auto_unbox = TRUE) |>
cat("aws = ", ., file=output, append = TRUE, sep = "\n")
jsonlite::toJSON(aws, auto_unbox = TRUE)
jsonlite::toJSON(aws, auto_unbox = TRUE, pretty = TRUE)
executor
system.file(paste0("inst/config.", executor), package = "MitoPilot")
system.file(paste0("config.", executor), package = "MitoPilot")
# Config file
config <- config %||% system.file(paste0("confi.", executor), package = "MitoPilot")
system.file(paste0("confi.", executor), package = "MitoPilot")
file.exists("")
devtools::load_all(".")
devtools::load_all(".")
?dir.delete
?unlink
devtools::load_all(".")
usethis::use_r("init_test_project")
mapping_fn <- system.file("mapping_test.csv", package = "MitoPilot")
mapping_fn <- system.file("mapping_test.csv", package = "MitoPilot") |>
read.csv()
accessions <- mapping_fn$ID
cur <- mapping[1,]
path = here::here()
dir.create(path, recursive = TRUE)
path = '/home/harpua/Jonah/MitoPilot/test'
# Get Data ----
file.path(path,"data") |>
dir.create(recursive = TRUE)
# Get Data ----
file.path(path,"data") |>
dir.create(recursive = TRUE)
acc <- cur$ID
pre <- str_sub(acc,1,6)
pre <- stringr::str_sub(acc,1,6)
suf <- stringr::str_extract(acc,"..$") |> stringr::str_pad(3, "left", "0")
cur <- list(...)
glue::glue(
"{i} of {nrow(mapping)}: {cur$ID} - {cur$Taxon}"
)
i <- 1
cur <- list(...)
glue::glue(
"{i} of {nrow(mapping)}: {cur$ID} - {cur$Taxon}"
)
cur <- mapping[1,]
glue::glue(
"{i} of {nrow(mapping)}: {cur$ID} - {cur$Taxon}"
)
glue::glue(
"{i} of {nrow(mapping)}: {cur$ID} - {cur$Taxon}"
) |> message()
acc <- cur$ID
pre <- stringr::str_sub(acc,1,6)
suf <- stringr::str_extract(acc,"..$") |> stringr::str_pad(3, "left", "0")
# R1
fn_R1 <- str_glue("data/{acc}_1.fastq.gz")
status <- str_glue(
"-t {fn_R1} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
# R1
fn_R1 <- glue::glue("data/{acc}_1.fastq.gz")
status <- glue::glue(
"-t {fn_R1} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
while(status=="incomplete"){
str_glue(
"curl",
"http://ftp.sra.ebi.ac.uk/vol1/fastq/{pre}/{suf}/{acc}/{acc}_1.fastq.gz",
"--silent -o {fn_R1}",
.sep=" "
) |> system()
status <- glue::glue(
"-t {fn_R1} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
}
status
status <- glue::glue(
"-t {fn_R1} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
while(status=="incomplete"){
glue::glue(
"curl",
"http://ftp.sra.ebi.ac.uk/vol1/fastq/{pre}/{suf}/{acc}/{acc}_1.fastq.gz",
"--silent -o {fn_R1}",
.sep=" "
) |> system()
status <- glue::glue(
"-t {fn_R1} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
}
glue::glue(
"curl",
"http://ftp.sra.ebi.ac.uk/vol1/fastq/{pre}/{suf}/{acc}/{acc}_1.fastq.gz",
"--silent -o {fn_R1}",
.sep=" "
)
cur
system.file("mapping_test.csv", package = "MitoPilot") |>
read.csv()
mapping <- system.file("mapping_test.csv", package = "MitoPilot") |>
read.csv()
# Get Data ----
file.path(path,"data") |>
dir.create(recursive = TRUE)
cur <- mapping[1,]
acc <- cur$ID
pre <- stringr::str_sub(acc,1,6)
suf <- stringr::str_extract(acc,"..$") |> stringr::str_pad(3, "left", "0")
# R1
fn_R1 <- glue::glue("data/{acc}_1.fastq.gz")
status <- glue::glue(
"-t {fn_R1} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
glue::glue(
"curl",
"http://ftp.sra.ebi.ac.uk/vol1/fastq/{pre}/{suf}/{acc}/{acc}_1.fastq.gz",
"--silent -o {fn_R1}",
.sep=" "
)
mapping <- system.file("mapping_test.csv", package = "MitoPilot") |>
read.csv()
cur <- mapping[1,]
glue::glue(
"{i} of {nrow(mapping)}: {cur$ID} - {cur$Taxon}"
) |> message()
acc <- cur$ID
pre <- stringr::str_sub(acc,1,6)
suf <- stringr::str_extract(acc,"..$") |> stringr::str_pad(3, "left", "0")
# R1
fn_R1 <- glue::glue("data/{acc}_1.fastq.gz")
status <- glue::glue(
"-t {fn_R1} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
glue::glue(
"curl",
"http://ftp.sra.ebi.ac.uk/vol1/fastq/{pre}/{suf}/{acc}/{acc}_1.fastq.gz",
"--silent -o {fn_R1}",
.sep=" "
)
glue::glue(
"curl",
"http://ftp.sra.ebi.ac.uk/vol1/fastq/{pre}/{suf}/{acc}/{acc}_1.fastq.gz",
"--silent -o {fn_R1}",
.sep=" "
)
fn_R1
# R1
fn_R1 <- file.path(path,"data",glue::glue("{acc}_1.fastq.gz"))
glue::glue(
"curl",
"http://ftp.sra.ebi.ac.uk/vol1/fastq/{pre}/{suf}/{acc}/{acc}_1.fastq.gz",
"--silent -o {fn_R1}",
.sep=" "
)
mapping <- system.file("mapping_test.csv", package = "MitoPilot") |>
read.csv()
# Get Data ----
file.path(path,"data") |>
dir.create(recursive = TRUE)
message("Fetching test data...")
i <- 1
purrr::pwalk(mapping, function(...){
cur <- list(...)
glue::glue(
"{i} of {nrow(mapping)}: {cur$ID} - {cur$Taxon}"
) |> message()
acc <- cur$ID
pre <- stringr::str_sub(acc,1,6)
suf <- stringr::str_extract(acc,"..$") |> stringr::str_pad(3, "left", "0")
# R1
fn_R1 <- file.path(path,"data",glue::glue("{acc}_1.fastq.gz"))
status <- glue::glue(
"-t {fn_R1} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
while(status=="incomplete"){
glue::glue(
"curl",
"http://ftp.sra.ebi.ac.uk/vol1/fastq/{pre}/{suf}/{acc}/{acc}_1.fastq.gz",
"--silent -o {fn_R1}",
.sep=" "
) |> system()
status <- glue::glue(
"-t {fn_R1} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
}
# R2
fn_R2 <- file.path(path,"data",glue::glue("{acc}_2.fastq.gz"))
status <- str_glue(
"-t {fn_R2} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
while(status=="incomplete"){
glue::glue(
"curl",
"http://ftp.sra.ebi.ac.uk/vol1/fastq/{pre}/{suf}/{acc}/{acc}_2.fastq.gz",
"--silent -o {fn_R2}",
.sep=" "
) |> system()
status <- glue::glue(
"-t {fn_R2} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
}
i <- i + 1
})
purrr::pwalk(mapping, function(...){
cur <- list(...)
glue::glue(
"{i} of {nrow(mapping)}: {cur$ID} - {cur$Taxon}"
) |> message()
acc <- cur$ID
pre <- stringr::str_sub(acc,1,6)
suf <- stringr::str_extract(acc,"..$") |> stringr::str_pad(3, "left", "0")
# R1
fn_R1 <- file.path(path,"data",glue::glue("{acc}_1.fastq.gz"))
status <- glue::glue(
"-t {fn_R1} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
while(status=="incomplete"){
glue::glue(
"curl",
"http://ftp.sra.ebi.ac.uk/vol1/fastq/{pre}/{suf}/{acc}/{acc}_1.fastq.gz",
"--silent -o {fn_R1}",
.sep=" "
) |> system()
status <- glue::glue(
"-t {fn_R1} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
}
# R2
fn_R2 <- file.path(path,"data",glue::glue("{acc}_2.fastq.gz"))
status <- glue::glue(
"-t {fn_R2} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
while(status=="incomplete"){
glue::glue(
"curl",
"http://ftp.sra.ebi.ac.uk/vol1/fastq/{pre}/{suf}/{acc}/{acc}_2.fastq.gz",
"--silent -o {fn_R2}",
.sep=" "
) |> system()
status <- glue::glue(
"-t {fn_R2} >/dev/null 2>&1 && echo 'complete' || echo 'incomplete' "
) |> system2("gzip", args=_, stdout=T)
}
i <- i + 1
})
path
devtools::document()
renv::snapshot(type = "explicit")
renv::settings$snapshot.type("explicit")
path
# Config file ----
config <- config %||% system.file(paste0("config.", executor), package = "MitoPilot")
config <-
system.file(paste0("config.", executor), package = "MitoPilot")
readLines(config) |>
stringr::str_replace("<<CONTAINER_ID>>", container) |>
writeLines(file.path(path, "nextflow.config"))
readLines(config) |>
stringr::str_replace("<<CONTAINER_ID>>", container)
readLines(config) |>
stringr::str_replace("<<CONTAINER_ID>>", container)
devtools::load_all(".")

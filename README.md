
<!-- README.md is generated from README.Rmd. Please edit that file -->

# `{MitoPilot}`

<!-- badges: start -->

[![Lifecycle:
experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
<!-- badges: end -->

# Overview

`{MitoPilot}` is a package for the assembly and annotation of
mitochondrial genomes from genome skimming data. The core application
consists of a [Nextflow](https://www.nextflow.io/docs/latest/index.html)
pipeline that is wrapped in an R package, which includes an R-Shiny
graphical interface to monitor and interact with processing parameters
and outputs. Currently the pipeline expects paired-end Illumina reads as
the raw input and performs the following steps:

1.  Mitogenome assembly
    - [fastp](https://github.com/OpenGene/fastp) for quality control and
      adapter trimming
    - [GetOrganelle](https://github.com/Kinggerm/GetOrganelle) for
      mitogenome assembly
    - [bowtie2](https://github.com/BenLangmead/bowtie2) for read mapping
      to calculate coverage and error rates.
2.  Mitogenome annotation
    - [MITOS2](https://gitlab.com/Bernt/MITOS) for rRNA and PCG
      annotation
    - [tRNAscan-SE](https://github.com/UCSC-LoweLab/tRNAscan-SE) for
      tRNA annotation
    - Custom scripts for gene boundary refinement and annotation file
      formatting
    - Validation to flag possible issues or known errors that would be
      rejected by NCBI GenBank
    - Manual curation of annotations using the integrated Shiny App.
3.  Data export
    - Custom scripts to export data in a format suitable for submission
      to NCBI GenBank

`{MitoPilot}` is currently optimized for Fish Mitogenome assembly, but
has been developed with modularity and extensibility in mind to
facilitate broader application in the future. In particular, the
included reference databases for assembly and annotation, along with the
default parameters for annotation curation and validation are highly
specific to fish mitogenomes. However, the reference databases and
annotation parameters can be easily updated. However, the custom logic
in the annotation curation and validation scripts would likely need to
be updated for optimal performance with other taxonomic groups. Because
all of the dependencies and reference data is contained on the
underlying Docker Image (currently hosted at `drleopold/MitoPilot`),
customization or extension will involve updating the Docker image
appropriately and specifying the new image in the Nextflow configuration
file (see below). The Dockerfile and default reference database file are
included in this repository for reference and a custom local Daocker
Image can be generated by modifying the Dockerfile as needed and running
`./docker/deploy-local.sh latest` in the repository root directory. More
detailed instructions on using custom reference databases (along with
other advanced customization) are coming soon.

# Installation

To use `{MitoPilot}`, you will need [R
(\>=4.0.0)](https://www.r-project.org/) and
[Nextflow](https://www.nextflow.io/docs/latest/install.html). In
addition, depending or where Nextflow will be executing the pipline
(e.g., locally or on a remote cluster), you may also need to install
[Docker](https://docs.docker.com/engine/install/) or
[Singularity](https://docs.sylabs.io/guides/latest/user-guide/quick_start.html#quick-installation-steps).

Once you have R and Nextflow installed, install `{MitoPilot}` in R from
GitHub:

``` r
if (!requireNamespace("BiocManager", quietly = TRUE)) {
    install.packages("BiocManager")
}
BiocManager::install("JonahVentures/MitoPilot")
```

Alternatively, you can clone this repository and install the package
locally from the project folder:

``` r
devtools::install()
```

# Usage

## Project Initialization

The `{MitoPilot}` workflow begins by initializing a new project with the
`new_project()` function. If running from within RStudio (recommended) a
new R-project will also be initialized and opened in a new RStudio
session.

``` r
MitoPilot::new_project(
  path = "path/to/project",             
  mapping = "path/to/mapping_file.csv", 
  executor = "local"     
)
```

- Path
  - The path specifies where the new project directory will be created.
    If no path is provided, the project will be created in the current
    working directory.
- Mapping File
  - The mapping file should be in csv format and must contain the
    columns ID (a unique identifier for each sample), Taxon (eg, species
    or genus name), along with R1, and R2 (specifying the forward and
    revers file names for the raw Illumina paired end data). In addition
    to the required fields any other sample metadata can be included in
    the mapping file. These fields can also be used when exporting files
    for NCBI GenBank Submissions, so metadata that is important for
    submission (e.g., BioSample ID) can be included here.
- Executor
  - The executor specifies where the computational work will be
    performed by Nextflow. For example choosing `loocal` will run the
    pipeline on the local machine, while `awsbatch` will run the
    pipeline on AWS Batch. Running `new_project()` will generate a
    executor-specific .config file in the project directory that must be
    edited to specify additional parameters for the pipeline to run.

## Nextflow configuration file

Initializing a new project will populate the `.config` file in the
project directory that may include place holders for important
parameters, in the format: `<<PARAMETER_NAME>>`. For example, all new
configuration files will include the line `rawDir = '<<RAW_DIR>>'`,
which should be updated to `rawDir = '/path/to/your/data'` indicating
the location of the raw data file specified in the mapping file. The
configuration files can also be modified to specify custom docker images
for one or more of the processing steps. After initializing a new
project you should review the `.config` file to ensure that all
necessary parameters are provided.

## Database

`{MitoPilot}` makes use of the Nextflow plugin,
[nf-sqldb](https://github.com/nextflow-io/nf-sqldb), to store and
retrieve processing parameters and information about the samples and
their processing status. The database is created automatically when the
project is initialized and is stored in the project directory
(`.sqlite`). The interactive MitoPilot GUI also interacts with this
database to allow you run the pipeline, modify parameters, and view the
results. When initializing a new project, default processing parameters
for the pipeline modules are stored in the database, but any processing
parameters can also be passed to the `new_project()` function to modify
the initial defaults. For example, the following options would modify
the allocated memory and GetOrganelle command line options :

``` r
MitoPilot::new_project(          
  mapping = "path/to/mapping_file.csv", 
  executor = "local",
  assemble_memory = 24,
  getOrganelle = "-F 'anonym' -R 20 -k '21,45,65,85,105,115' -J 1 -M 1 --expected-max-size 20000 --target-genome-size 16500"
)
```

## Test Data

`{MitoPilot}` include a function to create a test project to validate
the pipeline instillation and your execution environment settings.

``` r
init_test_project(
  path = "MitoPilot-test",
  executor = "local",
  full_size = FALSE
)
```

This function will load pre-filtered data sets for relatively quick
testing of the pipeline. Alternatively, you can set the parameter
`full_size=TRUE` to download all raw data for the test assemblies from
ENA (though you should be prepared to wait a while). An example mapping
file will be automatically populated in the project directory along with
a folder, `data/` with the raw data files. The configuraion file will
also be fully populated for the test project, but should still be
inspected. The Samples included in the test data have been selected to
not only include easily assembled mitogenomes, but also to demonstrate
many of the annotation curation / validation warnings and manual
curation features of the pipeline - hopefully your samples are not as
problematic!
